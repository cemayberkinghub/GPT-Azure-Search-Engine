{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "Now that we have our Search Engine loaded and running, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from app.embeddings import OpenAIEmbeddings\n",
    "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
    "from app.credentials import (\n",
    "    DATASOURCE_CONNECTION_STRING,\n",
    "    AZURE_SEARCH_API_VERSION,\n",
    "    AZURE_SEARCH_ENDPOINT,\n",
    "    AZURE_SEARCH_KEY,\n",
    "    COG_SERVICES_NAME,\n",
    "    COG_SERVICES_KEY,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    AZURE_OPENAI_KEY,\n",
    "    AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}\n",
    "params = {'api-version': AZURE_SEARCH_API_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Without Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index that we are going to query (from Notebook 01)\n",
    "index_name = \"cogsrch-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What are decission trees?\" \n",
    "\n",
    "# Try questions that you think might be answered or addressed in computer science papers in 2020-2021\n",
    "# And compare the results with the open version of ChatGPT\n",
    "# The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
    "\n",
    "# For Example:\n",
    "# What is CLP?\n",
    "# How Markov chains work?\n",
    "# What are some examples of reinforcement learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5c7e9f-42b9-4081-8975-648e4b31e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-cstevuxaqrxcm.search.windows.net/indexes/cogsrch-index/docs?api-version=2021-04-30-Preview&search=What are decission trees?&select=pages&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n",
      "200\n",
      "Results Found: 9745, Results Returned: 5\n"
     ]
    }
   ],
   "source": [
    "url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index_name + '/docs'\n",
    "url += '?api-version={}'.format(AZURE_SEARCH_API_VERSION)\n",
    "url += '&search={}'.format(QUESTION)\n",
    "url += '&select=pages'\n",
    "url += '&$top=5'  # You can change this to anything you need/want\n",
    "url += '&queryLanguage=en-us'\n",
    "url += '&queryType=semantic'\n",
    "url += '&semanticConfiguration=my-semantic-config'\n",
    "url += '&$count=true'\n",
    "url += '&speller=lexicon'\n",
    "url += '&answers=extractive|count-3'\n",
    "url += '&captions=extractive|highlight-false'\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "print(url)\n",
    "print(resp.status_code)\n",
    "\n",
    "search_results = resp.json()\n",
    "print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "015f0259-6609-4032-b8ae-09e95c69cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.99609375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A decision tree is a tree in which all childless nodes contain a  classification for the target concept, the nodes with children  contain one attribute Ai, and the edges are labeled with a value or  a condition for the attribute Ai in the parent node. The problem is  finding the minimum height decision tree that classifies the target  concept."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.99609375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "a decision  tree is a tree in which all childless nodes contain a  classification for the target concept, the nodes with children  contain a set of dialog acts in which the value for one slot  (attribute) ai in the structure is inquired, confirmed and  validated, and the edges are labeled with a value or a  condition for the attribute ai in the …"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.9833984375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "We begin a characterization of which functions require that for any deterministic algorithm for computing the function, there is some input for which the algorithm checks all the bits of the input.  1.1 Decision Trees  A decision tree is a tree representing the logical structure of certain algo- decision tree  rithms on various inputs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0508071v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.319580078125</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The definitions of decision trees in the context of func- tions mapping a product set domain X = X1 × · · · ×Xn  into a set Z are the obvious ones. Briefly, a DDT will be a rooted directed tree T in which each internal node v is labelled by a coordinate iv ∈ [n] and each leaf is labelled by an element of the output set Z ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0611037v2.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.31317138671875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A commonly used type of decision tree is the alphabetic binary tree, which uses (without loss of generality) “less than” versus ”greater than or equal to” tests in order to determine one of n outcome events."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0611166v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.236358642578125</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Introduction   Decision trees have two key merits when compared to other concept learners. First, they can manipulate a  large amount of information due to the small computational power that is needed for the creation of the  model of the underlying hypothesis; moreover, the representation of the model does not demand excessive  memory."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0110036v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.20989990234375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Decision trees are usually built top-down, using an al- gorithm similar to the one shown in Figure 1. Basi- cally, given a data set, a node is created and a test is selected for that node."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0205031v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.167327880859375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "We begin a characterization of which functions require that for any deterministic algorithm for computing the function, there is some input for which the algorithm checks all the bits of the input.  1.1 Decision Trees  A decision tree is a tree representing the logical structure of certain algo- decision tree  rithms on various inputs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers from semantic Search\n",
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "for result in search_results['@search.answers']:\n",
    "    if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "        display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "        display(HTML(result['text']))\n",
    "\n",
    "        \n",
    "# Results from key-word search\n",
    "file_content = dict()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "for result in search_results['value']:\n",
    "    if result['@search.rerankerScore'] > 0.4: # Show results that are at least 10% of the max possible score=4\n",
    "        display(HTML('<h5>' + result['metadata_storage_name'] + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: ' + str(result['@search.rerankerScore']) + '</h5>'))\n",
    "        display(HTML(result['@search.captions'][0]['text']))\n",
    "        file_content[result['metadata_storage_path']]={\n",
    "                            \"content\": result['pages'],  \n",
    "                            \"score\": result['@search.rerankerScore'], \n",
    "                            \"caption\": result['@search.captions'][0]['text']        \n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "## Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic search feature of Azure Cognitive Search service is pretty good. It gives us the top answers and also the top results with the corresponding file and the paragraph where the answers is possible located\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "## Using Azure OpenAI\n",
    "\n",
    "Of course we want OpenAI to give a better answer, so we instead of sending this results, we send the content(pages) of the search result articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "\n",
    "Notice that **the documents chunks are already done in Azure Search**. file_content dictionary (created in the cell above) contains the pages (chunks) of each document. So we dont really need to chunk them again, each doc page for sure will fit on the max tokens limit of davinci-003 and text-embeddding-ada-002 models.\n",
    "\n",
    "\n",
    "We will use a genius library call LangChain that wraps a lot of boiler plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Azure OpenAI create a deployment for the model \"text-embedding-ada-002\"\n",
    "# and VERY IMPORTANT name the deployment the same: \"text-embedding-ada-002\"\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key,value in file_content.items():\n",
    "    for page in value[\"content\"]:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 9.11 ms, total: 154 ms\n",
      "Wall time: 4.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(len(docs)>1):\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "else:\n",
    "    print(\"No results Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57429335-34d3-458a-b7c9-52482a0936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_db = db.similarity_search(QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17247488-7d14-4178-9add-31eb1afcbcbe",
   "metadata": {},
   "source": [
    "At this point we already have the most similar chuncks (in order of relevance given by the in-memory vector cosine similarity search) in docs_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c4788-715e-44dd-b2b8-3f1c3201e4e0",
   "metadata": {},
   "source": [
    "### Now we use GPT-3.5(Turbo) using map-reduce chain in order to stay within the limits of the allow model's token count\n",
    "\n",
    "for more information on the different types of prompts for these chains please see here:\n",
    "\n",
    "https://github.com/hwchase17/langchain/tree/master/langchain/chains/question_answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.3, max_tokens=500)\n",
    "chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='open-ai-pinternal.openai.azure.com', port=443): Read timed out. (read timeout=60).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 612 ms, sys: 93.2 ms, total: 705 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain({\"input_documents\": docs_db, \"question\": QUESTION}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cddb1cb-a4a0-4e2f-9f0c-4216b0f232b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Azure OpenAI ChatGPT Answer:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision trees are a fundamental programming abstraction used to determine one of n outcome events. They can be defined as a rooted directed tree in which each internal node is labeled by a coordinate and each leaf is labeled by an element of the output set. Decision trees are used to compute a function and have a cost on input x as the length of the root-leaf path T follows on input x. There are also zero-error randomized decision tree complexities R(T) and R(f). Decision trees are also used in dynamic branch prediction, where branches are predicted based on prior instances of the same and different branch instructions. There is a binary tree function where the internal nodes have labels from {1, 2, . . . , n} and whose leaves have labels from {0, 1}. If a node has label i, then the test performed at that node is to examine the ith bit of the input. If the result is 0, one descends into the left subtree, whereas if the result is 1, one descends into the right subtree. The label of the leaf so reached is the value of the function on the input. \n",
      "\n",
      "Sources:\n",
      "['https://demodatasetsp.blob.core.windows.net/arxivcs/0611/0611037v2.pdf', 'https://demodatasetsp.blob.core.windows.net/arxivcs/0508/0508071v1.pdf', 'https://demodatasetsp.blob.core.windows.net/arxivcs/0205/0205031v1.pdf']\n"
     ]
    }
   ],
   "source": [
    "answer = response['output_text']\n",
    "\n",
    "display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\n",
    "print(answer.split(\"SOURCES:\")[0])\n",
    "print(\"Sources:\")\n",
    "print(answer.split(\"SOURCES:\")[1].replace(\" \",\"\").split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea709347-248d-4a61-a79f-87fbd4f96439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to inspect the results from each top similar chunk\n",
    "# response['intermediate_steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Azure Cognitive Search give us the top results (context)\n",
    "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d4c66-7b06-447d-867e-09b7405cd1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7068a0-c758-4db6-bc2c-878fc60d47e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39adbe3a-ef29-42a6-9489-028dc7f59ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
